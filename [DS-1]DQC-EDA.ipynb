{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def open_files_in_dir(path):\n",
    "    files = {}\n",
    "    with os.scandir(path) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                files[entry.name.split('.')[0]] = pd.read_csv(entry)\n",
    "    return files\n",
    "\n",
    "basepath = 'C:/datasets/sales/'\n",
    "files_sales = open_files_in_dir(basepath)\n",
    "print(files_sales.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_sales['sales_train']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DQC class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first, we can create class which will encapsulate some information about given files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DQC:\n",
    "\n",
    "    def __init__(this, our_files):\n",
    "        this.files = our_files\n",
    "\n",
    "    def print_head(this, table_name):\n",
    "        print(this.files[table_name].head())\n",
    "\n",
    "    def are_there_any_duplicates(this):\n",
    "\n",
    "        sum_of_dupl = 0\n",
    "        tables = []\n",
    "        for file in this.files:\n",
    "            if this.files[file].duplicated().sum()!=0:\n",
    "                tables.append(file)\n",
    "                sum_of_dupl += this.files[file].duplicated().sum()\n",
    "\n",
    "            else: sum_of_dupl += this.files[file].duplicated().sum()\n",
    "\n",
    "        return f\"The amount of duplicated data in all the tables: {sum_of_dupl}; Tables with duplicates: {tables}\"\n",
    "\n",
    "    def are_there_any_null_values(this):\n",
    "\n",
    "        info = []\n",
    "\n",
    "        for file in this.files:\n",
    "            info.append(f\"Table {file} contains {this.files[file].isna().sum().sum()} empty raws\")\n",
    "\n",
    "        return info\n",
    "\n",
    "    def are_there_any_outliers(this):\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "        # add padding between the subplots\n",
    "        plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "        # draw boxplot for age in the 1st subplot\n",
    "        sns.boxplot(data=this.files['sales_train']['item_price'], ax=ax[0],)\n",
    "        ax[0].set_xlabel('item_price')\n",
    "\n",
    "        sns.boxplot(data=this.files['sales_train']['item_cnt_day'], ax=ax[1],)\n",
    "        ax[1].set_xlabel('item_cnt_day')\n",
    "\n",
    "    def columns_type_and_structure(this):\n",
    "\n",
    "        for file in this.files:\n",
    "            print(f'Table \"{file}\" with {this.files[file].shape[0]} values:')\n",
    "            print(this.files[file].dtypes)\n",
    "            print('\\n')\n",
    "\n",
    "    def are_there_any_negative_values(this):\n",
    "\n",
    "        temp_table = this.files['sales_train']\n",
    "        for col in temp_table.columns:\n",
    "            if temp_table[col].dtype != \"O\":\n",
    "                negs =  len(temp_table[temp_table[col]<0])\n",
    "                print(f\"The precent of negative values in sales_train table in {col} column: {round(negs*100/len(temp_table),5)}\")\n",
    "                if negs!=0:\n",
    "                    print('\\n')\n",
    "                    print(temp_table[temp_table[col]<0].head())\n",
    "                    print('\\n')\n",
    "\n",
    "    def the_returned(this):\n",
    "\n",
    "        sales_train = this.files['sales_train']\n",
    "        returned = sales_train[sales_train['item_cnt_day']<=0]\n",
    "\n",
    "        return returned\n",
    "\n",
    "    def is_actually_a_return(this):\n",
    "\n",
    "        returned = this.the_returned()\n",
    "        colors = sns.color_palette('pastel')[0:5]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Item ids:')\n",
    "        plt.pie(returned['item_id'].value_counts().head(), labels = returned['item_id'].value_counts().head().index, colors = colors)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Shop ids:')\n",
    "        plt.pie(returned['shop_id'].value_counts().head(), labels = returned['shop_id'].value_counts().head().index, colors = colors)\n",
    "\n",
    "        dif_date = returned['date'].nunique()\n",
    "        print('Amount of unique dates:',dif_date)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def inspect_table(data):\n",
    "    report = []\n",
    "\n",
    "    for t_name, df in data.items():\n",
    "        nan_report = df.isna().sum(0) / len(df)\n",
    "        unique_report = df.nunique()\n",
    "        types = df.infer_objects().dtypes.astype(str)\n",
    "        total = [len(df) for _ in range(len(df.columns))]\n",
    "\n",
    "        report.append( pd.DataFrame(\n",
    "            data=[\n",
    "                nan_report.values,\n",
    "                unique_report.values,\n",
    "                types,\n",
    "                total\n",
    "            ],\n",
    "            index=['nan_report', 'unique', 'dtype', 'total'],\n",
    "            columns= pd.MultiIndex.from_tuples([(col, t_name) for col in df.columns], names=[\"column_name\", \"table_name\"])\n",
    "        ))\n",
    "\n",
    "    return pd.concat(report, axis=1).transpose().reset_index().sort_values('column_name').set_index([\"column_name\", \"table_name\"])\n",
    "\n",
    "def dqc_inspection(data, report):\n",
    "    report = report.reset_index()\n",
    "    dqc_report = {}\n",
    "\n",
    "    # Step: schema key consistency\n",
    "    col_cnt = report.groupby('column_name').table_name.count().reset_index()\n",
    "    merging_cols = list(col_cnt[col_cnt.table_name > 1].column_name)\n",
    "    merging_cols__tables = report[report.column_name.isin(merging_cols)]\n",
    "\n",
    "    consistency_table__data = {}\n",
    "\n",
    "    for col in merging_cols:\n",
    "        table_names = merging_cols__tables[merging_cols__tables.column_name == col]\n",
    "\n",
    "        id_table_pairs = list(combinations(table_names.table_name.values, 2))\n",
    "\n",
    "        for l_table, r_table in id_table_pairs:\n",
    "\n",
    "            cmp_key = f\"[{col}] {l_table} - {r_table}\"\n",
    "            l_unique = set(data[l_table][col].unique())\n",
    "            r_unique = set(data[r_table][col].unique())\n",
    "\n",
    "            inter_len = len(l_unique.intersection(r_unique))\n",
    "            consistency_table__data__row = (len(l_unique) - inter_len, inter_len, len(r_unique) - inter_len)\n",
    "\n",
    "            consistency_table__data[cmp_key] = consistency_table__data__row\n",
    "\n",
    "    dqc_report[\"consistency_table\"] = pd.DataFrame(data=consistency_table__data.values(), columns=['left_cnt_only', 'intersect_len', 'right_cnt_only'], index=consistency_table__data.keys())\n",
    "\n",
    "    return dqc_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DQC methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc = DQC(files_sales)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.columns_type_and_structure()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6 tables, 2 of them contain test values.\n",
    "\n",
    "There are 2935849 values in train set and 214200 in test set (about 14:1).\n",
    "\n",
    "In test values we have amount of sold items in a month while in training set we use daily measure. Date is an object, can be converted in datetime type, then we also can lessen periods of time from date to look at some dynamics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####added######\n",
    "report = inspect_table(files_sales)\n",
    "dqc_base_report = dqc_inspection(files_sales, report)\n",
    "dqc_base_report['consistency_table']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In test set we have shops and items that will be unfamiliar to the future model since there is no such shops in items in the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.print_head('sales_train')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From first 5 rows we already see that there are returns (neg item_cnt_day). We can look at it closely."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.are_there_any_negative_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Negative values can be deleted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.is_actually_a_return()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Returns happen with a lot of different type of items in a lot of different shops. The dates are also pretty diverse."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.are_there_any_null_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No missing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.are_there_any_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Found some duplicated rows. Only 6, so it can be safely deleted or ignored."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqc.are_there_any_outliers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explicit outliers in item_price and item_cnt_day. We can look at them closely."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_sales['sales_train'][files_sales['sales_train']['item_price']>=300000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_sales['shops'][files_sales['shops']['shop_id']==12]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_sales['items'][(files_sales['items']['item_id']==11373)|(files_sales['items']['item_id']==20949)|(files_sales['items']['item_id']==6066)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "522 licenses in the set explains the standout price of the item. The same can be said about the amount of sold items per day: regular packing bags and delivery service.\n",
    "\n",
    "We also see that people tend to buy things in greater numbers through online stores.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.merge(files_sales['sales_train'], files_sales['shops'], on='shop_id', how = 'left')\n",
    "train = pd.merge(train, files_sales['items'], on='item_id', how = 'left')\n",
    "train = pd.merge(train, files_sales['item_categories'], on='item_category_id', how = 'left')\n",
    "\n",
    "test = pd.merge(files_sales['test'], files_sales['shops'], on='shop_id', how = 'left')\n",
    "test = pd.merge(test, files_sales['items'], on='item_id', how = 'left')\n",
    "test = pd.merge(test, files_sales['item_categories'], on='item_category_id', how = 'left')\n",
    "test.insert(loc=0,column='date_block_num',value=train['date_block_num'].max()+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ETL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def length(data):\n",
    "\n",
    "    data_len = data.shape[0]\n",
    "\n",
    "    print(f\"The amount of rows in data set: {data_len}\")\n",
    "    print('The amount of null values in train:',data.isna().sum().sum())\n",
    "\n",
    "def delete_neg_in_price_and_sales(data):\n",
    "\n",
    "    data = data[data['item_price']>0]\n",
    "    data = data[data['item_cnt_day']>0]\n",
    "\n",
    "    return data\n",
    "\n",
    "def delete_duplicates(data):\n",
    "\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "def date_format(data, col):\n",
    "\n",
    "    data[col] = pd.to_datetime(data[col], format='%d.%m.%Y')\n",
    "\n",
    "    data['year'] = data[col].dt.year\n",
    "    data['month'] = data[col].dt.month\n",
    "    data['day'] = data[col].dt.day\n",
    "\n",
    "    return data\n",
    "\n",
    "def to_file(data):\n",
    "\n",
    "    data.to_csv('C:/datasets/sales/after_etl.csv')\n",
    "\n",
    "    ###Only after date converting\n",
    "    ## через get_dummies слишком большие размерности выходят, какой-то другой метод брать или оставлять пока?\n",
    "def cat_to_num(data, col):\n",
    "    cat = [col for col in data.columns if data[col].dtype=='O']\n",
    "    data\n",
    "    return pd.get_dummies(data, columns = col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = delete_neg_in_price_and_sales(train)\n",
    "train = date_format(train, 'date')\n",
    "train['year-month'] = train['date'].dt.to_period('M')\n",
    "#train = train[train['item_price']<300000]\n",
    "#train = train[train['item_cnt_day']<800]\n",
    "train = delete_duplicates(train)\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['shop_name'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.loc[train['shop_name']=='!Якутск Орджоникидзе, 56 фран','shop_name'] = 'Якутск Орджоникидзе, 56'\n",
    "train.loc[train['shop_name']=='!Якутск ТЦ \"Центральный\" фран','shop_name'] = 'Якутск ТЦ \"Центральный\"'\n",
    "train.loc[train['shop_name']=='Москва ТК \"Буденовский\" (пав.К7)','shop_name'] = 'Москва ТК \"Буденовский\"'\n",
    "train.loc[train['shop_name']=='Москва ТК \"Буденовский\" (пав.А2)','shop_name'] = 'Москва ТК \"Буденовский\"'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.loc[test['shop_name']=='!Якутск Орджоникидзе, 56 фран','shop_name'] = 'Якутск Орджоникидзе, 56'\n",
    "test.loc[test['shop_name']=='!Якутск ТЦ \"Центральный\" фран','shop_name'] = 'Якутск ТЦ \"Центральный\"'\n",
    "test.loc[test['shop_name']=='Москва ТК \"Буденовский\" (пав.К7)','shop_name'] = 'Москва ТК \"Буденовский\"'\n",
    "test.loc[test['shop_name']=='Москва ТК \"Буденовский\" (пав.А2)','shop_name'] = 'Москва ТК \"Буденовский\"'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should have answers to the following questions:\n",
    "- What I'm working with ?\n",
    "- What are the main patterns and tendencies with my data ?\n",
    "- How do my data entities interact ?\n",
    "- What should I do with my data to obtain good features ?\n",
    "- What are the problems with the probable prediction ?\n",
    "- How could I manually make predict based on data ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#general dynamics\n",
    "plt.title('General dynamics of amount of sold items per time')\n",
    "time_series=train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n",
    "time_series.plot();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We clearly see that the series is not stationary. It has a downtrend and apparently some seasonality, around a year."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_org = train.groupby([\"year-month\",\"shop_name\"])\\\n",
    "    [\"date\",\"item_cnt_day\"].agg({\"item_cnt_day\":\"sum\"}).reset_index()\n",
    "date_org.columns = ['year-month','shop_name','item_cnt_month']\n",
    "top = date_org.sort_values(by='item_cnt_month', ascending=False).head(10)\n",
    "sns.barplot(data=top, x=\"item_cnt_month\", y=\"year-month\", palette='pastel')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "More often people were buying in 2013, probably due to lower prices. There is also a pattern: in winter, at the end and at the beginning of the year, sales are usually higher."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####added######\n",
    "plt.title('General dynamics of mean item price per time')\n",
    "time_series=train.groupby([\"date_block_num\"])[\"item_price\"].mean()\n",
    "time_series.plot();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####added######\n",
    "t = train[train['item_price']<300000]\n",
    "t = t[t['item_cnt_day']<800]\n",
    "plt.title('General dependency between amount of sold items and price')\n",
    "plt.ylabel('item_cnt')\n",
    "plt.xlabel('item_price')\n",
    "plt.scatter(t['item_price'], t['item_cnt_day'], alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we see the lesser the prices the higher the sales."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####added######\n",
    "shops_look_up = train.groupby(['shop_name','date_block_num','item_name']).agg({'item_cnt_day': 'sum', 'item_price':'mean'}).reset_index()\n",
    "shops_look_up['income'] = round(shops_look_up['item_cnt_day']*shops_look_up['item_price'],2)\n",
    "shops_look_up = shops_look_up.groupby(['shop_name','date_block_num',]).agg({'item_cnt_day': 'sum', 'item_price':'sum','income':'sum'}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shops_look_up.groupby('shop_name').agg({'item_cnt_day': ['mean','std', 'sum'],'date_block_num':'count'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on deviation we can tell that 2 shops(Жуковский ул.Чкалова 39м² and Новосибирск ТРЦ \"Галерея Новосибирск\") were active only for a month. The lower std compared to mean the more homogeneous the sales are."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####added######\n",
    "shops_list = shops_look_up['shop_name'].unique()\n",
    "fig, axs = plt.subplots(2, 2, figsize=(25, 15))\n",
    "\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[:15]))], x=\"date_block_num\", y=\"item_cnt_day\", hue=\"shop_name\", ax=axs[0][0])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[15:31]))], x=\"date_block_num\", y=\"item_cnt_day\", hue=\"shop_name\",ax=axs[0][1])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[31:46]))], x=\"date_block_num\", y=\"item_cnt_day\", hue=\"shop_name\",ax=axs[1][0])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[46:]))], x=\"date_block_num\", y=\"item_cnt_day\", hue=\"shop_name\",ax=axs[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shops_list = shops_look_up['shop_name'].unique()\n",
    "fig, axs = plt.subplots(2, 2, figsize=(25, 15))\n",
    "\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[:15]))], x=\"date_block_num\", y=\"income\", hue=\"shop_name\", ax=axs[0][0])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[15:31]))], x=\"date_block_num\", y=\"income\", hue=\"shop_name\",ax=axs[0][1])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[31:46]))], x=\"date_block_num\", y=\"income\", hue=\"shop_name\",ax=axs[1][0])\n",
    "sns.lineplot(data=shops_look_up[(28<=shops_look_up['date_block_num'])&(shops_look_up['shop_name'].isin(shops_list[46:]))], x=\"date_block_num\", y=\"income\", hue=\"shop_name\",ax=axs[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While looking at the last 6 month dynamics in every available shop we see that most shops are pretty stable with Москва ТЦ \"Семеновский\" being the leader. Online shops tend to have high peaks in block 32. 2 shops were also closed during this period of time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_eda = train.groupby(['year','month']).agg({'item_price': 'mean','item_name': 'count',}).reset_index()\n",
    "for idx, col in enumerate(train_eda.columns[2:]):\n",
    "    plt.figure()\n",
    "    sns.lineplot(data=train_eda, x='month', y=col, hue='year').set_title(f\"Dynamics for {col}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, prices per item in 2015 is way higher than the were 1-2 years ago. For some reason every august the also tend to get bigger. We have reverse situation in amount of sold items."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "\n",
    "p_year_patterns = train.groupby(['day', 'month', 'year']).agg({\n",
    "    'item_name': 'count',\n",
    "}).reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(25, 15))\n",
    "\n",
    "for month in range(1,13):\n",
    "    sns.lineplot(data=p_year_patterns[p_year_patterns.month == month], x='day', y='item_name', hue='year', ax=axs[(month - 1) // 4][(month - 1) % 4]).set_title(f\"{col} - dynamic in {calendar.month_name[month]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#for numerical feathures\n",
    "tr = train.copy()\n",
    "tr.drop(['shop_id','item_id','item_category_id'],inplace=True, axis=1)\n",
    "\n",
    "corr_matrix = tr.corr(method='spearman')\n",
    "sns.heatmap(corr_matrix, annot=True);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a correlation between the values obtained from the date. Before modeling some of it will be removed.\n",
    "\n",
    "The biggest correlation target formed with item_price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorial feathures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['shop_name'].value_counts().head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see names have a pattern: location - type - shop name. We can extract some information here, maybe it will be useful."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['location'] = train['shop_name'].str.split(\" \").str[0]\n",
    "train['shop_type'] = train['shop_name'].str.split(\" \").str[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['location'] = test['shop_name'].str.split(\" \").str[0]\n",
    "test['shop_type'] = test['shop_name'].str.split(\" \").str[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['location'].value_counts()\n",
    "train['shop_type'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.loc[train['location']=='Цифровой','location'] = 'Цифровой склад'\n",
    "train.loc[train['location']=='Сергиев','location'] = 'Сергиев посад'\n",
    "train.loc[train['location']=='!Якутск','location'] = 'Якутск'\n",
    "train.loc[train['shop_type']=='Орджоникидзе,','shop_type'] = 'Не указан'\n",
    "train.loc[train['shop_type']=='Посад','shop_type'] = 'ТЦ'\n",
    "train.loc[train['shop_type']=='\"Распродажа\"','shop_type'] = 'Не указан'\n",
    "train.loc[train['shop_type']=='(Плехановская,','shop_type'] = 'Не указан'\n",
    "train.loc[train['shop_type']=='склад','shop_type'] = 'Не указан'\n",
    "train.loc[train['shop_type']=='ул.','shop_type'] = 'Не указан'\n",
    "train.loc[train['shop_type']=='МТРЦ','shop_type'] = 'ТРЦ'\n",
    "train.loc[train['shop_type']=='Торговля','shop_type'] = 'Не указан'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.loc[test['location']=='Цифровой','location'] = 'Цифровой склад'\n",
    "test.loc[test['location']=='Сергиев','location'] = 'Сергиев посад'\n",
    "test.loc[test['location']=='!Якутск','location'] = 'Якутск'\n",
    "test.loc[test['shop_type']=='Орджоникидзе,','shop_type'] = 'Не указан'\n",
    "test.loc[test['shop_type']=='Посад','shop_type'] = 'ТЦ'\n",
    "test.loc[test['shop_type']=='\"Распродажа\"','shop_type'] = 'Не указан'\n",
    "test.loc[test['shop_type']=='(Плехановская,','shop_type'] = 'Не указан'\n",
    "test.loc[test['shop_type']=='склад','shop_type'] = 'Не указан'\n",
    "test.loc[test['shop_type']=='ул.','shop_type'] = 'Не указан'\n",
    "test.loc[test['shop_type']=='МТРЦ','shop_type'] = 'ТРЦ'\n",
    "test.loc[test['shop_type']=='Торговля','shop_type'] = 'Не указан'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the names we also can see some random symbols, \"!\" for example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train[train['shop_name'].str.contains('Якутск')==True]['shop_name'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['shop_name'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['item_category'] = train['item_category_name'].str.split(\" - \").str[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['item_category'] = test['item_category_name'].str.split(\" - \").str[0]\n",
    "test[\"subcat\"] = test[\"item_category_name\"].str.split(\" - \").map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train[\"subcat\"] = train[\"item_category_name\"].str.split(\" - \").map(\n",
    "    lambda x: x[1].strip() if len(x) > 1 else x[0].strip()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in ['location','shop_type','shop_name', 'item_category_name']:\n",
    "    top_10_locs = train[col].value_counts().head(10)\n",
    "    top_10_locs = top_10_locs.to_frame().reset_index()\n",
    "    top_10_locs.columns = [col, 'count']\n",
    "    sns.barplot(data=top_10_locs, x='count', y=col, palette = 'pastel')\n",
    "    plt.title(f'Top 10 of {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.xlabel('Count')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moscow and it's shops are apperently the most common ones. ТЦ are quite popular."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What can be done with data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- First of all, we can make data take form that will be more convinient for our main goal. It means that info can be grouped by shops and items, than for every group we can calculate the amount of soled products. Due to the fact that price of an item is not fixed we can try to take mean value.\n",
    "\n",
    "- As it was stated earlier, seasonality and trend should be looked into.\n",
    "\n",
    "- While working with time series, it is a common practice to create \"lagged\" copies of the series. Lagging a time series means to shift its values forward one or more time steps, or equivalently, to shift the times in its index backward one or more steps. We can also do that."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}